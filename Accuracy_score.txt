Accuracy Score:

	- a performace evaluation method
	- based on the confusion metrics

	- Accuracy_score = (TP+TN)/(TP+TN+FP+FN)
	- if the data is balanced and if the score is >70%, the created model is good
			<70%, model requires improvement
	- if the data is imbalanced data(unequal data eg, more number of non-cancer data and less number of cancer data, the m/c will predict non cancer patient more accurately but might not 		predict cancer patient even if the accuracy score is 98%.)
	- by taking value_count for the last column,we can find if the data is balanced or imbalanced. If the data is imbalanced, further performance evaluation methods needs to be applied
	- imbalanced data can be converted to balanced data

#Performance_Evaluation:

from sklearn.metrics import confusion_matrix
cm =  confusion_matrix(y_test,y_predict)
cm

# Accuracy Score Calculation:

from sklearn.metrics import accuracy_score
score = accuracy_score(y_test,y_predict)
score

-The accuracy score differs in different machines and in different runtimes for same file. this is becz 70% used for training data is picked randomly.

Random State:

- Inorder to get same performance we can define how to choose the training and testing data, for this we use random_state which we define a value
- experimentally proven that, if u give random_state value as 1,0,42 the machine performs well
